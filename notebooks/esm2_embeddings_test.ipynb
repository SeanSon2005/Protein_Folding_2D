{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "install_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run using docker run --gpus all -it --rm nvcr.io/nvidia/pytorch:25.08-py3\n",
                "!pip install transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
                "import csv\n",
                "import json\n",
                "from typing import Any, Dict, Optional, Tuple, List, Set\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from torch.nn.utils.rnn import pad_sequence\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "from collections import defaultdict\n",
                "import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "constants_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Constants\n",
                "DATA_FILE = \"test.tsv\"\n",
                "OUTPUT_FILE = \"esm2_embeddings_test.pt\"\n",
                "MODEL_NAME = \"nvidia/esm2_t48_15B_UR50D\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "parsing_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "def parse_test_tsv(file_path):\n",
                "    sequences = defaultdict(list)\n",
                "    \n",
                "    # 3-letter to 1-letter map\n",
                "    aa_map = {\n",
                "        'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E', 'PHE': 'F',\n",
                "        'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LYS': 'K', 'LEU': 'L',\n",
                "        'MET': 'M', 'ASN': 'N', 'PRO': 'P', 'GLN': 'Q', 'ARG': 'R',\n",
                "        'SER': 'S', 'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y',\n",
                "    }\n",
                "\n",
                "    print(f\"Reading {file_path}...\")\n",
                "    with open(file_path, 'r') as f:\n",
                "        reader = csv.reader(f, delimiter='\\t')\n",
                "        header = next(reader) # Skip header \"id\"\n",
                "        \n",
                "        for row in reader:\n",
                "            if not row: continue\n",
                "            # Format: 3JRN_LYS_8\n",
                "            parts = row[0].split('_')\n",
                "            if len(parts) != 3:\n",
                "                continue\n",
                "                \n",
                "            pdb_id = parts[0]\n",
                "            aa_3 = parts[1]\n",
                "            pos = int(parts[2])\n",
                "            \n",
                "            aa_1 = aa_map.get(aa_3, 'X')\n",
                "            sequences[pdb_id].append((pos, aa_1))\n",
                "            \n",
                "    # Reconstruct sequences\n",
                "    final_data = []\n",
                "    print(f\"Reconstructing sequences for {len(sequences)} proteins...\")\n",
                "    for pdb_id, residue_list in sequences.items():\n",
                "        # Sort by position\n",
                "        residue_list.sort(key=lambda x: x[0])\n",
                "        \n",
                "        # Concatenate\n",
                "        seq = \"\".join([x[1] for x in residue_list])\n",
                "        final_data.append({\"chain_id\": pdb_id, \"input\": seq})\n",
                "        \n",
                "    return final_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dataset_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "class ProteinTestDataset(Dataset):\n",
                "    def __init__(self, data: List[Dict], input_vocab: Dict[str, int]):\n",
                "        self.data = data\n",
                "        self.input_vocab = input_vocab\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.data)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.data[idx]\n",
                "        input_seq = [self.input_vocab.get(c, self.input_vocab.get(\"<UNK>\")) for c in row['input']]\n",
                "        return torch.tensor(input_seq, dtype=torch.long), row['chain_id']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "model_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load ESM2 model and tokenizer\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "model = AutoModelForMaskedLM.from_pretrained(\n",
                "    MODEL_NAME,\n",
                "    trust_remote_code=True\n",
                ").to(device)\n",
                "model.eval()\n",
                "model.config.output_hidden_states = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "prepare_data_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare Vocabulary\n",
                "CANONICAL_AA = set(\"ACDEFGHIKLMNPQRSTVWY\")\n",
                "pad_token_id = tokenizer.pad_token_id\n",
                "unk_token_id = tokenizer.unk_token_id\n",
                "cls_token_id = tokenizer.cls_token_id\n",
                "eos_token_id = tokenizer.eos_token_id\n",
                "\n",
                "if pad_token_id is None:\n",
                "    raise ValueError(\"Tokenizer is missing required special tokens.\")\n",
                "\n",
                "input_chars = sorted(CANONICAL_AA.union({\"X\"}))\n",
                "input_vocab = {\"<PAD>\": pad_token_id, \"<UNK>\": unk_token_id}\n",
                "for char in input_chars:\n",
                "    token_id = tokenizer.convert_tokens_to_ids(char)\n",
                "    if token_id == unk_token_id or token_id is None:\n",
                "        token_id = unk_token_id\n",
                "    input_vocab[char] = token_id\n",
                "\n",
                "# Load Data\n",
                "data = parse_test_tsv(DATA_FILE)\n",
                "dataset = ProteinTestDataset(data, input_vocab)\n",
                "\n",
                "BATCH_SIZE = 1 # Keep small for safety on big model\n",
                "input_pad_idx = input_vocab[\"<PAD>\"]\n",
                "\n",
                "def collate_fn(batch):\n",
                "    input_seqs, chain_ids = zip(*batch)\n",
                "    lengths = torch.tensor([seq.size(0) for seq in input_seqs], dtype=torch.long)\n",
                "    seqs_with_specials = []\n",
                "    for seq in input_seqs:\n",
                "        seqs_with_specials.append(\n",
                "            torch.cat([\n",
                "                torch.tensor([cls_token_id], dtype=torch.long),\n",
                "                seq,\n",
                "                torch.tensor([eos_token_id], dtype=torch.long),\n",
                "            ])\n",
                "        )\n",
                "    padded_inputs = pad_sequence(seqs_with_specials, batch_first=True, padding_value=input_pad_idx)\n",
                "    return padded_inputs, lengths, chain_ids\n",
                "\n",
                "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "generation_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "all_chain_ids = []\n",
                "all_lengths = []\n",
                "all_embeddings = []\n",
                "\n",
                "print(\"Starting embedding generation...\")\n",
                "with torch.no_grad():\n",
                "    for batch_inputs, batch_lengths, batch_chain_ids in tqdm(dataloader, desc=\"Generating embeddings\"):\n",
                "        attention_mask = (batch_inputs != input_pad_idx).long().to(device)\n",
                "        batch_inputs = batch_inputs.to(device)\n",
                "\n",
                "        outputs = model(\n",
                "            input_ids=batch_inputs,\n",
                "            attention_mask=attention_mask,\n",
                "        )\n",
                "        # Last layer: (batch_size, seq_len_with_specials, hidden_dim)\n",
                "        hidden = outputs.hidden_states[-1]\n",
                "        \n",
                "        batch_size = hidden.size(0)\n",
                "\n",
                "        for b in range(batch_size):\n",
                "            seq_len = batch_lengths[b].item()\n",
                "            \n",
                "            # (L, D) float32, still on GPU\n",
                "            # Strip CLS (index 0) and EOS (index seq_len + 1)\n",
                "            seq_hidden = hidden[b, 1:seq_len + 1, :]\n",
                "            seq_hidden_cpu = seq_hidden.detach().cpu().contiguous() # (L, D), float32\n",
                "\n",
                "            all_chain_ids.append(batch_chain_ids[b])\n",
                "            all_lengths.append(seq_len)\n",
                "            all_embeddings.append(seq_hidden_cpu)\n",
                "\n",
                "# Save to file\n",
                "print(f\"Saving {len(all_chain_ids)} embeddings to {OUTPUT_FILE}...\")\n",
                "obj = {\n",
                "    \"chain_ids\": all_chain_ids,\n",
                "    \"lengths\": torch.tensor(all_lengths, dtype=torch.int32),\n",
                "    \"embeddings\": all_embeddings,\n",
                "}\n",
                "torch.save(obj, OUTPUT_FILE)\n",
                "print(\"Done!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
